import matplotlib.pyplot as plt
import cv2
import mediapipe as mp
import sys
import math
import numpy as np
import tempfile
import uuid
from PIL import Image, ImageDraw, ImageFont

from app.services.video_utils_ver2 import rotated_frame_generator

def put_korean_text(frame, text, position, font_size=24, color=(255, 255, 255)):
    """OpenCV í”„ë ˆì„ì— í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    try:
        # í”„ë ˆì„ ë³µì‚¬í•˜ì—¬ ì›ë³¸ ë³´ì¡´
        frame_copy = frame.copy()
        
        # BGR -> RGB ë³€í™˜
        img_pil = Image.fromarray(cv2.cvtColor(frame_copy, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        # í°íŠ¸ ë¡œë“œ ì‹œë„
        font = None
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",  # Windows ë§‘ì€ ê³ ë”•
            "malgun.ttf",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Linux
            "/System/Library/Fonts/AppleGothic.ttf",  # macOS
        ]
        
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue
        
        if font is None:
            font = ImageFont.load_default()
        
        # BGR -> RGB ìƒ‰ìƒ ë³€í™˜ (PILì€ RGB ì‚¬ìš©)
        rgb_color = (color[2], color[1], color[0])
        draw.text(position, text, font=font, fill=rgb_color)
        
        # RGB -> BGR ë³€í™˜í•˜ì—¬ ë°˜í™˜
        result = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        return result
    except Exception as e:
        print(f"put_korean_text error: {e}")
        # ì—ëŸ¬ ì‹œ cv2.putTextë¡œ í´ë°±
        cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        return frame

def extract_front_knee_foot_xs_lunge_style(frame_gen, show_video=False, save_video_path=None):
    from app.utils.angle_utils import calculate_angle
    mp_pose = mp.solutions.pose
    knee_xs = []
    foot_xs = []
    knee_angles = []
    hip_y_list = []
    knee_y_list = []
    width, height = None, None
    video_writer = None
    frame_penalties = []  # í”„ë ˆì„ë³„ íŒ¨ë„í‹° ì €ì¥
    total_penalty = 0
    frame_count = 0

    with mp_pose.Pose(static_image_mode=False) as pose:
        for frame in frame_gen:
            if width is None or height is None:
                height, width = frame.shape[:2]
                # VideoWriter ì´ˆê¸°í™” (save_video_pathê°€ ì£¼ì–´ì§„ ê²½ìš°)
                if save_video_path is not None:
                    # H.264 ì½”ë± ì‹œë„ (ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ìµœê³ )
                    for codec in ['avc1', 'h264', 'H264', 'x264', 'X264']:
                        fourcc = cv2.VideoWriter_fourcc(*codec)
                        video_writer = cv2.VideoWriter(save_video_path, fourcc, 30, (width, height))
                        if video_writer.isOpened():
                            print(f"Using codec: {codec}")
                            break
                    
                    if video_writer is None or not video_writer.isOpened():
                        # ëª¨ë“  H.264 ì½”ë± ì‹¤íŒ¨ì‹œ mp4vë¡œ í´ë°±
                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                        video_writer = cv2.VideoWriter(save_video_path, fourcc, 30, (width, height))
                        print("Fallback to mp4v codec")

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = pose.process(image_rgb)
            
            if result.pose_landmarks:
                landmarks = result.pose_landmarks.landmark
                nose_x = landmarks[0].x * width
                left_shoulder_x = landmarks[11].x * width
                right_shoulder_x = landmarks[12].x * width
                left_knee_x = landmarks[25].x * width
                right_knee_x = landmarks[26].x * width
                left_foot_x = landmarks[31].x * width
                right_foot_x = landmarks[32].x * width

                # ì•ë‹¤ë¦¬ íŒë³„ ë° ì¸ë±ìŠ¤ ê²°ì •
                if nose_x > right_shoulder_x:
                    look_direction = "right"
                else:
                    look_direction = "left"

                if look_direction == "right":
                    if right_foot_x > left_foot_x:
                        knee_x = right_knee_x
                        foot_x = right_foot_x
                        front_foot_x = right_foot_x
                        hip_idx, knee_idx, ankle_idx = 24, 26, 28
                        # ìˆ˜ì§ì„  ì •ë ¬ìš© (ë°˜ëŒ€ìª½ = ì™¼ìª½)
                        opp_shoulder_idx, opp_hip_idx, opp_knee_idx = 11, 23, 25
                    else:
                        knee_x = left_knee_x
                        foot_x = left_foot_x
                        front_foot_x = left_foot_x
                        hip_idx, knee_idx, ankle_idx = 23, 25, 27
                        # ìˆ˜ì§ì„  ì •ë ¬ìš© (ë°˜ëŒ€ìª½ = ì˜¤ë¥¸ìª½)
                        opp_shoulder_idx, opp_hip_idx, opp_knee_idx = 12, 24, 26
                else:
                    if left_foot_x < right_foot_x:
                        knee_x = left_knee_x
                        foot_x = left_foot_x
                        front_foot_x = left_foot_x
                        hip_idx, knee_idx, ankle_idx = 23, 25, 27
                        # ìˆ˜ì§ì„  ì •ë ¬ìš© (ë°˜ëŒ€ìª½ = ì˜¤ë¥¸ìª½)
                        opp_shoulder_idx, opp_hip_idx, opp_knee_idx = 12, 24, 26
                    else:
                        knee_x = right_knee_x
                        foot_x = right_foot_x
                        front_foot_x = right_foot_x
                        hip_idx, knee_idx, ankle_idx = 24, 26, 28
                        # ìˆ˜ì§ì„  ì •ë ¬ìš© (ë°˜ëŒ€ìª½ = ì™¼ìª½)
                        opp_shoulder_idx, opp_hip_idx, opp_knee_idx = 11, 23, 25

                knee_xs.append(knee_x)
                foot_xs.append(foot_x)
                
                # ìˆ˜ì§ì„  ì •ë ¬ ê³„ì‚° (ì–´ê¹¨-ì—‰ë©ì´-ë°˜ëŒ€ìª½ ë¬´ë¦)
                opp_shoulder = (landmarks[opp_shoulder_idx].x * width, landmarks[opp_shoulder_idx].y * height)
                opp_hip = (landmarks[opp_hip_idx].x * width, landmarks[opp_hip_idx].y * height)
                opp_knee_pt = (landmarks[opp_knee_idx].x * width, landmarks[opp_knee_idx].y * height)
                vertical_angle = calc_three_point_angle(opp_shoulder, opp_hip, opp_knee_pt)
                vertical_deviation = abs(180 - vertical_angle)

                # ë¬´ë¦ì´ ë°œëë³´ë‹¤ ì•ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€ íŒë³„ ë° íŒ¨ë„í‹° ê³„ì‚°
                if look_direction == "right":
                    over_distance = max(0, knee_x - foot_x)
                else:
                    over_distance = max(0, foot_x - knee_x)
                
                penalty = calc_penalty(over_distance, threshold=10, max_penalty=100) if over_distance > 0 else 0
                total_penalty += penalty
                frame_count += 1

                # ì•ë‹¤ë¦¬ ë¬´ë¦ ê°ë„ ê³„ì‚° ë° ë°°ì—´ ì €ì¥
                hip = (landmarks[hip_idx].x * width, landmarks[hip_idx].y * height)
                knee = (landmarks[knee_idx].x * width, landmarks[knee_idx].y * height)
                ankle = (landmarks[ankle_idx].x * width, landmarks[ankle_idx].y * height)
                knee_angle = calculate_angle(hip, knee, ankle)
                knee_angles.append(knee_angle)
                hip_y_list.append(int(hip[1]))
                knee_y_list.append(int(knee[1]))

                # ë¹„ë””ì˜¤ì— ì‹œê°ì  í”¼ë“œë°± ì¶”ê°€ (save_video_pathê°€ ìˆì„ ë•Œë§Œ)
                if save_video_path is not None:
                    # 1ï¸âƒ£ ë°œë ê¸°ì¤€ ìˆ˜ì§ì„  (ë¬´ë¦ì´ ë„˜ìœ¼ë©´ ë¹¨ê°„ìƒ‰, ì•ˆë„˜ìœ¼ë©´ ì´ˆë¡ìƒ‰)
                    line_color = (0, 0, 255) if over_distance > 0 else (0, 255, 0)
                    cv2.line(frame, (int(front_foot_x), 0), (int(front_foot_x), height), line_color, 2)
                    
                    # 2ï¸âƒ£ ìˆ˜ì§ì„  ì •ë ¬ ì‹œê°í™” (ì–´ê¹¨-ì—‰ë©ì´-ë°˜ëŒ€ìª½ ë¬´ë¦)
                    # í¸ì°¨ì— ë”°ë¼ ìƒ‰ìƒ ê²°ì •: â‰¤10ë„ ì´ˆë¡, 10~20ë„ ë…¸ë‘, >20ë„ ë¹¨ê°•
                    if vertical_deviation <= 10:
                        vertical_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (ì¢‹ìŒ)
                    elif vertical_deviation <= 20:
                        vertical_color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (ì¤‘ê°„)
                    else:
                        vertical_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚˜ì¨)
                    
                    # ì–´ê¹¨-ì—‰ë©ì´-ë°˜ëŒ€ìª½ ë¬´ë¦ì„ ì—°ê²°í•˜ëŠ” ì„ 
                    cv2.line(frame, (int(opp_shoulder[0]), int(opp_shoulder[1])), 
                             (int(opp_hip[0]), int(opp_hip[1])), vertical_color, 3)
                    cv2.line(frame, (int(opp_hip[0]), int(opp_hip[1])), 
                             (int(opp_knee_pt[0]), int(opp_knee_pt[1])), vertical_color, 3)
                    
                    # ì„¸ ì ì— ì› í‘œì‹œ
                    cv2.circle(frame, (int(opp_shoulder[0]), int(opp_shoulder[1])), 8, vertical_color, -1)
                    cv2.circle(frame, (int(opp_hip[0]), int(opp_hip[1])), 8, vertical_color, -1)
                    cv2.circle(frame, (int(opp_knee_pt[0]), int(opp_knee_pt[1])), 8, vertical_color, -1)
                    
                    # 3ï¸âƒ£ ê°€ë™ë²”ìœ„ ì‹œê°í™” (ì—‰ë©ì´-ë¬´ë¦ ë†’ì´ ì°¨ì´)
                    hip_y_val = int(hip[1])
                    knee_y_val = int(knee[1])
                    range_diff = knee_y_val - hip_y_val  # ì–‘ìˆ˜: ë¬´ë¦ì´ ì—‰ë©ì´ë³´ë‹¤ ì•„ë˜
                    
                    # ê°€ë™ë²”ìœ„ ìƒ‰ìƒ ê²°ì •: â‰¤25í”½ì…€ ì´ˆë¡(ì¢‹ìŒ), 25~50í”½ì…€ ë…¸ë‘(ì¤‘ê°„), >50í”½ì…€ ë¹¨ê°•(ë‚˜ì¨)
                    if abs(range_diff) <= 25:
                        range_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (ì¢‹ìŒ - ë¬´ë¦ì´ ì—‰ë©ì´ ë†’ì´ì— ê°€ê¹Œì›€)
                    elif abs(range_diff) <= 50:
                        range_color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (ì¤‘ê°„)
                    else:
                        range_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (ë‚˜ì¨ - ë” ê¹Šê²Œ ë‚´ë ¤ê°€ì•¼ í•¨)
                    
                    # ì—‰ë©ì´ ë†’ì´ ê°€ë¡œì„ 
                    cv2.line(frame, (0, hip_y_val), (width, hip_y_val), (255, 165, 0), 2)  # ì£¼í™©ìƒ‰ (ì—‰ë©ì´)
                    
                    # ë¬´ë¦ ë†’ì´ ê°€ë¡œì„ 
                    cv2.line(frame, (0, knee_y_val), (width, knee_y_val), range_color, 2)
                    
                    # ì—‰ë©ì´-ë¬´ë¦ ë†’ì´ ì°¨ì´ë¥¼ ì„¸ë¡œì„ ìœ¼ë¡œ í‘œì‹œ
                    mid_x = int((hip[0] + knee[0]) / 2)
                    cv2.line(frame, (mid_x, hip_y_val), (mid_x, knee_y_val), range_color, 3)
                    
                    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                    mp.solutions.drawing_utils.draw_landmarks(
                        frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS
                    )
                    
                    # ========== í†µí•© ì •ë³´ ë°•ìŠ¤ (í•œê¸€ ì§€ì›) ==========
                    current_accuracy = max(0, 100 - (total_penalty / frame_count if frame_count > 0 else 0))
                    
                    # í†µí•© ì •ë³´ ë°•ìŠ¤ ë°°ê²½
                    cv2.rectangle(frame, (10, 10), (280, 130), (40, 40, 40), -1)
                    cv2.rectangle(frame, (10, 10), (280, 130), (100, 100, 100), 2)
                    
                    # í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§
                    # ë¬´ë¦ ì •í™•ë„ ìƒ‰ìƒ
                    acc_color = (0, 255, 0) if current_accuracy >= 90 else ((0, 255, 255) if current_accuracy >= 70 else (0, 0, 255))
                    
                    frame = put_korean_text(frame, f"ì •í™•ë„: {current_accuracy:.1f}%", (20, 15), font_size=22, color=acc_color)
                    frame = put_korean_text(frame, f"ìˆ˜ì§ ì •ë ¬: {vertical_deviation:.1f}Â°", (20, 50), font_size=20, color=vertical_color)
                    frame = put_korean_text(frame, f"ê°€ë™ë²”ìœ„: {abs(range_diff)}px", (20, 85), font_size=20, color=range_color)

                if show_video:
                    cv2.imshow("Lunge Video", frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
            
            # í”„ë ˆì„ ì €ì¥ (ëœë“œë§ˆí¬ê°€ ìˆë“  ì—†ë“ )
            if video_writer is not None:
                video_writer.write(frame)

    if show_video:
        cv2.destroyAllWindows()
    if video_writer is not None:
        video_writer.release()
    return knee_xs, foot_xs, knee_angles, hip_y_list, knee_y_list

def calc_penalty(over_distance, threshold=10, max_penalty=100):
    x = max(0, over_distance)
    exp_input = min((x / threshold) ** 2, 10)
    penalty = math.exp(exp_input) - 1
    return min(penalty, max_penalty)

def plot_knee_foot_distance(knee_xs, foot_xs):
    distances = [knee - foot for knee, foot in zip(knee_xs, foot_xs)]
    penalties = []
    penalty_frames = []
    for idx, d in enumerate(distances):
        # ìŒìˆ˜(=ë¬´ë¦ì´ ë°œëë³´ë‹¤ ì•ìœ¼ë¡œ ë‚˜ê°)ì¼ ë•Œë§Œ íŒ¨ë„í‹° ë¶€ì—¬
        penalty = calc_penalty(-d) if d < 0 else 0
        penalties.append(penalty)
        if penalty > 0:
            penalty_frames.append(idx)
    avg_penalty = sum(penalties) / len(penalties) if penalties else 0
    accuracy = max(0, 100 - avg_penalty)

    plt.figure(figsize=(10, 5))
    plt.plot(distances, label="Knee - Foot X Distance")
    plt.axhline(0, color='red', linestyle='--', label='Foot X')
    # íŒ¨ë„í‹°ê°€ ë°œìƒí•œ í”„ë ˆì„ì— ë§ˆì»¤ í‘œì‹œ
    if penalty_frames:
        plt.scatter(np.array(penalty_frames), np.array([distances[i] for i in penalty_frames]), 
                    color='red', label='Penalty (Accuracyâ†“)', zorder=5)
    plt.xlabel("Frame")
    plt.ylabel("Knee X - Foot X (pixels)")
    plt.title(f"Distance from Foot to Knee (X axis) Over Frames\nAccuracy: {accuracy:.1f}%")
    plt.legend()
    plt.tight_layout()
    plt.show()

def calc_three_point_angle(a, b, c):
    # ê° bë¥¼ ê¸°ì¤€ìœ¼ë¡œ a-b-cì˜ ê°ë„ë¥¼ êµ¬í•¨
    ba = np.array([a[0] - b[0], a[1] - b[1]])
    bc = np.array([c[0] - b[0], c[1] - b[1]])
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)
    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
    return np.degrees(angle)

def analyze_vertical_alignment(frame_gen):
    mp_pose = mp.solutions.pose
    width, height = None, None
    vertical_angles = []

    with mp_pose.Pose(static_image_mode=False) as pose:
        for frame in frame_gen:
            if width is None or height is None:
                height, width = frame.shape[:2]
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = pose.process(image_rgb)
            if not result.pose_landmarks:
                continue
            landmarks = result.pose_landmarks.landmark
            nose_x = landmarks[0].x * width
            right_shoulder_x = landmarks[12].x * width
            left_foot_x = landmarks[31].x * width
            right_foot_x = landmarks[32].x * width

            # ì•ë‹¤ë¦¬ íŒë³„
            if nose_x > right_shoulder_x:
                look_direction = "right"
            else:
                look_direction = "left"

            if look_direction == "right":
                if right_foot_x > left_foot_x:
                    hip_idx, shoulder_idx, opp_knee_idx = 24, 12, 25
                else:
                    hip_idx, shoulder_idx, opp_knee_idx = 23, 11, 26
            else:
                if left_foot_x < right_foot_x:
                    hip_idx, shoulder_idx, opp_knee_idx = 23, 11, 26
                else:
                    hip_idx, shoulder_idx, opp_knee_idx = 24, 12, 25

            hip = (landmarks[hip_idx].x * width, landmarks[hip_idx].y * height)
            shoulder = (landmarks[shoulder_idx].x * width, landmarks[shoulder_idx].y * height)
            opp_knee = (landmarks[opp_knee_idx].x * width, landmarks[opp_knee_idx].y * height)

            angle = calc_three_point_angle(shoulder, hip, opp_knee)
            vertical_angles.append(angle)

    return vertical_angles

def lunge_video_level2(video_bytes: bytes, feedback_id: int) -> dict:
    print("="*50)
    print("ğŸ¯ LEVEL 2 ë¶„ì„ ì‹œì‘ (ì¤‘ê¸‰)")
    print("ë¶„ì„ í•­ëª©: ë¬´ë¦-ë°œë ì •ë ¬, ìˆ˜ì§ì„  ì •ë ¬, ê°€ë™ë²”ìœ„")
    print("="*50)
    
    import tempfile
    import uuid
    from app.utils.minio_client import client as minio_client, bucket_name
    import app.utils.minio_client as minio_client_module

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as input_tmp:
        input_tmp.write(video_bytes)
        input_path = input_tmp.name

    # 1ë‹¨ê³„: ë¶„ì„ê°’ ì¶”ì¶œ (ë¹„ë””ì˜¤ ìƒì„± ì—†ì´)
    frame_gen = rotated_frame_generator(input_path)
    knee_xs, foot_xs, knee_angles, hip_y_list, knee_y_list = extract_front_knee_foot_xs_lunge_style(frame_gen, show_video=False)

    # 2ë‹¨ê³„: ì‹œê°ì  í”¼ë“œë°±ì´ í¬í•¨ëœ ë¹„ë””ì˜¤ ìƒì„±
    output_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    output_path = output_tmp.name
    output_tmp.close()
    
    frame_gen_visual = rotated_frame_generator(input_path)
    extract_front_knee_foot_xs_lunge_style(frame_gen_visual, show_video=False, save_video_path=output_path)

    # 3ë‹¨ê³„: FFmpegë¡œ ë¸Œë¼ìš°ì € ìŠ¤íŠ¸ë¦¬ë° ìµœì í™” (faststart)
    import subprocess
    optimized_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    optimized_path = optimized_tmp.name
    optimized_tmp.close()
    
    try:
        # FFmpegë¡œ H.264 ì¬ì¸ì½”ë”© + faststart (moov atomì„ íŒŒì¼ ì•ìœ¼ë¡œ)
        subprocess.run([
            'ffmpeg', '-i', output_path,
            '-c:v', 'libx264',  # H.264 ì½”ë±
            '-preset', 'fast',  # ë¹ ë¥¸ ì¸ì½”ë”©
            '-movflags', '+faststart',  # ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”
            '-y',  # ë®ì–´ì“°ê¸°
            optimized_path
        ], check=True, capture_output=True)
        
        # ìµœì í™”ëœ íŒŒì¼ë¡œ êµì²´
        final_output = optimized_path
        print(f"Optimized video with FFmpeg: {final_output}")
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg optimization failed: {e.stderr.decode()}")
        # FFmpeg ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
        final_output = output_path
    except FileNotFoundError:
        print("FFmpeg not found, using original video")
        final_output = output_path

    # --- ìˆ˜ì§ì„  ì •ë ¬ ë¶„ì„ ---
    vertical_angles = analyze_vertical_alignment(rotated_frame_generator(input_path))
    # 180ë„ì— ê°€ê¹Œìš´ ê°’ì´ ìˆ˜ì§, 10ë„ ì´ë‚´ë©´ OK
    vertical_deviation = [abs(180 - angle) for angle in vertical_angles]
    n = len(vertical_deviation)
    k = max(1, int(n * 0.1))
    best_vertical = np.mean(sorted(vertical_deviation)[:k]) if k > 0 else 180

    vertical_tolerance = 10  # ë„
    if best_vertical <= vertical_tolerance:
        vertical_score = 100
        vertical_level = "ì¢‹ìŒ"
    elif best_vertical <= vertical_tolerance * 2:
        vertical_score = max(0, 100 - ((best_vertical - vertical_tolerance) / vertical_tolerance) * 100)
        vertical_level = "ì¤‘ê°„"
    else:
        vertical_score = 0
        vertical_level = "ë‚˜ì¨"
    vertical_score = min(vertical_score, 100)

    distances = [knee - foot for knee, foot in zip(knee_xs, foot_xs)]
    penalties = []
    penalty_frames = []
    for idx, d in enumerate(distances):
        penalty = calc_penalty(-d) if d < 0 else 0
        penalties.append(penalty)
        if penalty > 0:
            penalty_frames.append(idx)
    avg_penalty = sum(penalties) / len(penalties) if penalties else 0
    knee_accuracy = max(0, 100 - avg_penalty)

    # ê¸°ì¡´ movement_range ê³„ì‚° (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    sorted_diffs = sorted([h - k for h, k in zip(hip_y_list, knee_y_list)])
    n = len(sorted_diffs)
    k = max(1, int(n * 0.1))
    movement_range = round(np.mean(sorted_diffs[-k:]), 2)

    # test.pyì™€ ë™ì¼í•œ ê°€ë™ë²”ìœ„ í‰ê°€ ê³µì‹
    diff_y_list = [knee - hip for knee, hip in zip(knee_y_list, hip_y_list)]
    sorted_diffs = sorted(diff_y_list, key=lambda x: abs(x))
    n = len(sorted_diffs)
    k = max(1, int(n * 0.1))
    best_range_avg = np.mean(sorted_diffs[:k]) if k > 0 else 0

    tolerance = 25  # í”½ì…€
    if abs(best_range_avg) <= tolerance:
        score = 100
        level = "ì¢‹ìŒ"
    elif abs(best_range_avg) <= tolerance * 2:
        score = max(0, 100 - ((abs(best_range_avg) - tolerance) / tolerance) * 100)
        level = "ì¤‘ê°„"
    else:
        score = 0
        level = "ë‚˜ì¨"
    score = min(score, 100)

    bucket_name = "levelupfit-videos"
    object_name = f"{uuid.uuid4()}.mp4"
    try:
        import os
        file_size = os.path.getsize(final_output)
        with open(final_output, 'rb') as file_data:
            minio_client.put_object(
                bucket_name=bucket_name,
                object_name=object_name,
                data=file_data,
                length=file_size,
                content_type="video/mp4"
            )
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        import os
        if os.path.exists(input_path):
            os.remove(input_path)
        if os.path.exists(output_path):
            os.remove(output_path)
        if 'optimized_path' in locals() and os.path.exists(optimized_path) and optimized_path != final_output:
            os.remove(optimized_path)
    video_url = f"https://{minio_client_module.MINIO_URL}/{bucket_name}/{object_name}"
    
    # í—ˆë¦¬ ìˆ˜ì§ ê°ë„ ì ìˆ˜ëŠ” vertical_score (0~100)
    # ë‘ ì ìˆ˜ì˜ í‰ê· ì„ ìµœì¢… accuracyë¡œ ì‚¬ìš©
    accuracy = round((knee_accuracy + vertical_score) / 2, 1)
    
    # LLM í”¼ë“œë°± ìƒì„± (ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback)
    from app.services.llm_feedback import generate_feedback_level2
    feedback_text = generate_feedback_level2(
        accuracy=accuracy,
        movement_range=round(score, 1),
        knee_accuracy=knee_accuracy,
        vertical_score=vertical_score
    )
    print(round(score, 1), level, round(best_range_avg, 2), round(vertical_score, 1), vertical_level, round(best_vertical, 2))

    return {
        "feedback_id": feedback_id,
        "video_url": video_url,
        "feedback_text": feedback_text,
        "accuracy": accuracy,
        "movementRange": round(score, 1)
    }

def make_feedback_intermediate(vertical_score, knee_accuracy, movement_range):
    feedback = []
    if knee_accuracy >= 90:
        feedback.append("ë¬´ë¦ì´ ë°œë ì•ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šì•˜ì–´ìš”. ì¢‹ì•„ìš”!")
    else:
        feedback.append("ë¬´ë¦ì´ ë°œë ì•ìœ¼ë¡œ ë‚˜ê°”ìŠµë‹ˆë‹¤. ì£¼ì˜í•˜ì„¸ìš”!")
    if vertical_score >= 90:
        feedback.append("ì–´ê¹¨, ì—‰ë©ì´, ë°˜ëŒ€ìª½ ë°œì´ ì˜ ìˆ˜ì§ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.")
    elif vertical_score >= 60:
        feedback.append("ìˆ˜ì§ ì •ë ¬ì´ ì•½ê°„ ë¶€ì¡±í•©ë‹ˆë‹¤.\nì—‰ë©ì´ì™€ ì–´ê¹¨, ë°˜ëŒ€ìª½ ë°œì´ ì¼ì§ì„ ì´ ë˜ë„ë¡ ì‹ ê²½ì¨ë³´ì„¸ìš”.")
    else:
        feedback.append("ìˆ˜ì§ ì •ë ¬ì´ ë§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\nìì„¸ë¥¼ ë” ê³§ê²Œ ìœ ì§€í•˜ì„¸ìš”.")
    if movement_range >= 80:
        feedback.append("ê°€ë™ë²”ìœ„ê°€ ì¶©ë¶„í•©ë‹ˆë‹¤.")
    else:
        feedback.append("ê°€ë™ë²”ìœ„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ê¹Šê²Œ ë‚´ë ¤ê°€ë³´ì„¸ìš”.")
    return "\n".join(feedback)
