import matplotlib.pyplot as plt
import cv2
import mediapipe as mp
import sys
import math
import numpy as np
import tempfile
import uuid

from app.services.video_utils_ver2 import rotated_frame_generator

def process_lunge_frame(frame, pose, width, height, calculate_angle=None, tolerance=25):
    """
    1. Mediapipeë¡œ ëœë“œë§ˆí¬ ì¶”ì¶œ
    2. ì•ë‹¤ë¦¬ íŒë³„ ë° ì¢Œí‘œ/ê°ë„ ê³„ì‚°
    3. ê¸°ì¤€ ë°œëì— yì¶• ì„ (ì´ˆë¡/ë¹¨ê°•) ê·¸ë¦¬ê¸°
    4. ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
    5. ë¶„ì„ê°’ ë°˜í™˜
    """
    mp_pose = mp.solutions.pose  # â† ì´ ì¤„ ì¶”ê°€!
    result = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    if not result.pose_landmarks:
        return frame, None, None, None, None, None

    landmarks = result.pose_landmarks.landmark
    nose_x = landmarks[0].x * width
    left_shoulder_x = landmarks[11].x * width
    right_shoulder_x = landmarks[12].x * width
    left_knee_x = landmarks[25].x * width
    right_knee_x = landmarks[26].x * width
    left_foot_x = landmarks[31].x * width
    right_foot_x = landmarks[32].x * width

    # ì•ë‹¤ë¦¬ íŒë³„ ë° ì¸ë±ìŠ¤ ê²°ì •
    if nose_x > right_shoulder_x:
        look_direction = "right"
    else:
        look_direction = "left"

    if look_direction == "right":
        if right_foot_x > left_foot_x:
            knee_x = right_knee_x
            foot_x = right_foot_x
            hip_idx, knee_idx, ankle_idx = 24, 26, 28
        else:
            knee_x = left_knee_x
            foot_x = left_foot_x
            hip_idx, knee_idx, ankle_idx = 23, 25, 27
    else:
        if left_foot_x < right_foot_x:
            knee_x = left_knee_x
            foot_x = left_foot_x
            hip_idx, knee_idx, ankle_idx = 23, 25, 27
        else:
            knee_x = right_knee_x
            foot_x = right_foot_x
            hip_idx, knee_idx, ankle_idx = 24, 26, 28

    # ë¬´ë¦ ê°ë„ ê³„ì‚° ë° yì¢Œí‘œ
    if calculate_angle:
        hip = (landmarks[hip_idx].x * width, landmarks[hip_idx].y * height)
        knee = (landmarks[knee_idx].x * width, landmarks[knee_idx].y * height)
        ankle = (landmarks[ankle_idx].x * width, landmarks[ankle_idx].y * height)
        knee_angle = calculate_angle(hip, knee, ankle)
        hip_y = int(hip[1])
        knee_y = int(knee[1])
    else:
        knee_angle = None
        hip_y = None
        knee_y = None

    # ê¸°ì¤€ ë°œëì— yì¶• ì„  (ë¬´ë¦ì´ ë°œë ë„˜ìœ¼ë©´ ë¹¨ê°„ìƒ‰)
    color = (0, 255, 0)
    if knee_x > foot_x:
        color = (0, 0, 255)
    cv2.line(frame, (int(foot_x), 0), (int(foot_x), height), color, 2)

    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° (ì´ê²Œ ì„ ì„ ë®ì–´ë²„ë¦¼)
    mp.solutions.drawing_utils.draw_landmarks(
        frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS
    )

    # ë¬´ë¦ ìœ„ì¹˜ì— xì¶•(ê°€ë¡œ) ì„ ì„ draw_landmarks ì´í›„ì— ê·¸ë¦¬ê¸°!
    if knee_y is not None and hip_y is not None:
        range_color = (0, 0, 255)
        if abs(knee_y - hip_y) <= tolerance:
            range_color = (0, 255, 0)
        cv2.line(frame, (0, int(knee_y)), (width, int(knee_y)), range_color, 2)

    return frame, knee_x, foot_x, knee_angle, hip_y, knee_y

def save_landmark_video(input_path, output_path):
    """
    ëœë“œë§ˆí¬ì™€ ê¸°ì¤€ì„ ì´ ê·¸ë ¤ì§„ ì˜ìƒì„ ì €ì¥ë§Œ í•¨ (ë¶„ì„ê°’ì€ ë°˜í™˜í•˜ì§€ ì•ŠìŒ)
    """
    import mediapipe as mp
    import cv2
    from app.utils.angle_utils import calculate_angle

    cap = cv2.VideoCapture(input_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    
    # H.264 ì½”ë± ì‹œë„ (ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ìµœê³ )
    out = None
    for codec in ['avc1', 'h264', 'H264', 'x264', 'X264']:
        fourcc = cv2.VideoWriter_fourcc(*codec)
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        if out.isOpened():
            print(f"Using codec: {codec}")
            break
    
    if out is None or not out.isOpened():
        # ëª¨ë“  H.264 ì½”ë± ì‹¤íŒ¨ì‹œ mp4vë¡œ í´ë°±
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        print("Fallback to mp4v codec")
    
    if not out.isOpened():
        cap.release()
        raise Exception("VideoWriter ì´ˆê¸°í™” ì‹¤íŒ¨")

    mp_pose = mp.solutions.pose
    with mp_pose.Pose(static_image_mode=False) as pose:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame, *_ = process_lunge_frame(
                frame, pose, width, height, calculate_angle=calculate_angle
            )
            out.write(frame)
    cap.release()
    out.release()

def extract_front_knee_foot_xs_lunge_style(frame_gen, show_video=False):
    """
    ë¶„ì„ê°’ë§Œ ì¶”ì¶œ (ì˜ìƒ ì €ì¥ X)
    """
    from app.utils.angle_utils import calculate_angle
    mp_pose = mp.solutions.pose
    knee_xs = []
    foot_xs = []
    knee_angles = []
    hip_y_list = []
    knee_y_list = []
    width, height = None, None

    with mp_pose.Pose(static_image_mode=False) as pose:
        for frame in frame_gen:
            if width is None or height is None:
                height, width = frame.shape[:2]
            _, knee_x, foot_x, knee_angle, hip_y, knee_y = process_lunge_frame(
                frame, pose, width, height, calculate_angle=calculate_angle
            )
            if knee_x is not None:
                knee_xs.append(knee_x)
                foot_xs.append(foot_x)
                knee_angles.append(knee_angle)
                hip_y_list.append(hip_y)
                knee_y_list.append(knee_y)
            if show_video:
                cv2.imshow("Lunge Video", frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
    if show_video:
        cv2.destroyAllWindows()
    return knee_xs, foot_xs, knee_angles, hip_y_list, knee_y_list

def calc_penalty(over_distance, threshold=10, max_penalty=100):
    x = max(0, over_distance)
    exp_input = min((x / threshold) ** 2, 10)
    penalty = math.exp(exp_input) - 1
    return min(penalty, max_penalty)

def plot_knee_foot_distance(knee_xs, foot_xs):
    distances = [knee - foot for knee, foot in zip(knee_xs, foot_xs)]
    penalties = []
    penalty_frames = []
    for idx, d in enumerate(distances):
        # ìŒìˆ˜(=ë¬´ë¦ì´ ë°œëë³´ë‹¤ ì•ìœ¼ë¡œ ë‚˜ê°)ì¼ ë•Œë§Œ íŒ¨ë„í‹° ë¶€ì—¬
        penalty = calc_penalty(-d) if d < 0 else 0
        penalties.append(penalty)
        if penalty > 0:
            penalty_frames.append(idx)
    avg_penalty = sum(penalties) / len(penalties) if penalties else 0
    accuracy = max(0, 100 - avg_penalty)

    plt.figure(figsize=(10, 5))
    plt.plot(distances, label="Knee - Foot X Distance")
    plt.axhline(0, color='red', linestyle='--', label='Foot X')
    # íŒ¨ë„í‹°ê°€ ë°œìƒí•œ í”„ë ˆì„ì— ë§ˆì»¤ í‘œì‹œ
    if penalty_frames:
        plt.scatter(np.array(penalty_frames), np.array([distances[i] for i in penalty_frames]), 
                    color='red', label='Penalty (Accuracyâ†“)', zorder=5)
    plt.xlabel("Frame")
    plt.ylabel("Knee X - Foot X (pixels)")
    plt.title(f"Distance from Foot to Knee (X axis) Over Frames\nAccuracy: {accuracy:.1f}%")
    plt.legend()
    plt.tight_layout()
    plt.show()

def lunge_video_ver2(video_bytes: bytes, feedback_id: int) -> dict:
    print("="*50)
    print("ğŸ¯ LEVEL 1 ë¶„ì„ ì‹œì‘ (ê¸°ë³¸)")
    print("ë¶„ì„ í•­ëª©: ë¬´ë¦-ë°œë ì •ë ¬, ê°€ë™ë²”ìœ„")
    print("="*50)
    
    import tempfile
    import uuid
    from app.utils.minio_client import client as minio_client, bucket_name
    import app.utils.minio_client as minio_client_module

    # 1. ì›ë³¸ ì˜ìƒ ì„ì‹œíŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as input_tmp:
        input_tmp.write(video_bytes)
        input_path = input_tmp.name

    # 2. ëœë“œë§ˆí¬ ì˜ìƒ ì„ì‹œíŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as output_tmp:
        output_path = output_tmp.name

    # 3. ëœë“œë§ˆí¬ ì˜ìƒ ìƒì„±
    save_landmark_video(input_path, output_path)

    # 3-1. FFmpegë¡œ ë¸Œë¼ìš°ì € ìŠ¤íŠ¸ë¦¬ë° ìµœì í™” (faststart)
    import subprocess
    optimized_tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    optimized_path = optimized_tmp.name
    optimized_tmp.close()
    
    try:
        # FFmpegë¡œ H.264 ì¬ì¸ì½”ë”© + faststart (moov atomì„ íŒŒì¼ ì•ìœ¼ë¡œ)
        subprocess.run([
            'ffmpeg', '-i', output_path,
            '-c:v', 'libx264',  # H.264 ì½”ë±
            '-preset', 'fast',  # ë¹ ë¥¸ ì¸ì½”ë”©
            '-movflags', '+faststart',  # ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”
            '-y',  # ë®ì–´ì“°ê¸°
            optimized_path
        ], check=True, capture_output=True)
        
        # ìµœì í™”ëœ íŒŒì¼ë¡œ êµì²´
        final_output = optimized_path
        print(f"Optimized video with FFmpeg: {final_output}")
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg optimization failed: {e.stderr.decode()}")
        # FFmpeg ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
        final_output = output_path
    except FileNotFoundError:
        print("FFmpeg not found, using original video")
        final_output = output_path

    # 4. ë¶„ì„ (ê¸°ì¡´ëŒ€ë¡œ input_path ì‚¬ìš©)
    frame_gen = rotated_frame_generator(input_path)
    knee_xs, foot_xs, knee_angles, hip_y_list, knee_y_list = extract_front_knee_foot_xs_lunge_style(frame_gen, show_video=False)

    distances = [knee - foot for knee, foot in zip(knee_xs, foot_xs)]
    penalties = []
    penalty_frames = []
    for idx, d in enumerate(distances):
        penalty = calc_penalty(-d) if d < 0 else 0
        penalties.append(penalty)
        if penalty > 0:
            penalty_frames.append(idx)
    avg_penalty = sum(penalties) / len(penalties) if penalties else 0
    accuracy = max(0, 100 - avg_penalty)

    # ê¸°ì¡´ movement_range ê³„ì‚° (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    sorted_diffs = sorted([h - k for h, k in zip(hip_y_list, knee_y_list)])
    n = len(sorted_diffs)
    k = max(1, int(n * 0.1))
    movement_range = round(np.mean(sorted_diffs[-k:]), 2)

    # test.pyì™€ ë™ì¼í•œ ê°€ë™ë²”ìœ„ í‰ê°€ ê³µì‹
    diff_y_list = [knee - hip for knee, hip in zip(knee_y_list, hip_y_list)]
    sorted_diffs = sorted(diff_y_list, key=lambda x: abs(x))
    n = len(sorted_diffs)
    k = max(1, int(n * 0.1))
    best_range_avg = np.mean(sorted_diffs[:k]) if k > 0 else 0

    tolerance = 25  # í”½ì…€
    if abs(best_range_avg) <= tolerance:
        score = 100
        level = "ì¢‹ìŒ"
    elif abs(best_range_avg) <= tolerance * 2:
        score = max(0, 100 - ((abs(best_range_avg) - tolerance) / tolerance) * 100)
        level = "ì¤‘ê°„"
    else:
        score = 0
        level = "ë‚˜ì¨"
    score = min(score, 100)

    # 5. MinIOì— ëœë“œë§ˆí¬ ì˜ìƒ ì—…ë¡œë“œ
    bucket_name = "levelupfit-videos"
    object_name = f"{uuid.uuid4()}.mp4"
    
    try:
        import os
        file_size = os.path.getsize(final_output)
        with open(final_output, 'rb') as file_data:
            minio_client.put_object(
                bucket_name=bucket_name,
                object_name=object_name,
                data=file_data,
                length=file_size,
                content_type="video/mp4"
            )
        video_url = f"https://{minio_client_module.MINIO_URL}/{bucket_name}/{object_name}"
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        import os
        if os.path.exists(input_path):
            os.remove(input_path)
        if os.path.exists(output_path):
            os.remove(output_path)
        if 'optimized_path' in locals() and os.path.exists(optimized_path) and optimized_path != final_output:
            os.remove(optimized_path)
    
    feedback_text = make_feedback_basic(accuracy, round(score, 1))
    print(round(score, 1), level, round(best_range_avg, 2))

    return {
        "feedback_id": feedback_id,
        "video_url": video_url,
        "feedback_text": feedback_text,
        "accuracy": accuracy,
        "movementRange": round(score, 1)
    }

def make_feedback_basic(accuracy, movement_range):
    feedback = []
    if accuracy >= 90:
        feedback.append("ë¬´ë¦ì´ ë°œë ì•ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šì•˜ì–´ìš”. ì¢‹ì•„ìš”!")
    else:
        feedback.append("ë¬´ë¦ì´ ë°œë ì•ìœ¼ë¡œ ë‚˜ê°”ìŠµë‹ˆë‹¤. ì£¼ì˜í•˜ì„¸ìš”!")
    if movement_range >= 80:
        feedback.append("ê°€ë™ë²”ìœ„ê°€ ì¶©ë¶„í•©ë‹ˆë‹¤.")
    else:
        feedback.append("ê°€ë™ë²”ìœ„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ê¹Šê²Œ ë‚´ë ¤ê°€ë³´ì„¸ìš”.")
    return "\n".join(feedback)
